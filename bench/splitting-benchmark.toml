# TODO(awav): --tf_xla_auto_jit=2 fails
# cmd = 'TF_XLA_FLAGS="--tf_xla_auto_jit=2" python ./bench.py --warmup 10 --repeat 100 --logdir "{uid}"'
cmd = 'python ./bench.py --warmup 10 --repeat 100 --logdir "{uid}"'

# [[exp]]
# cmd = '{split_xla_flags} {cmd} {kind} -i "({num}, {dim})"'
# uid = './{rootdir}/{kind}/{float}-split/shape-{num}-{dim}'

# rootdir = "logs"
# split_xla_flags = 'XLA_FLAGS="--xla_enable_hlo_passes_only=split-intermediate-tensors" '
# kind = "outerprod-with-itself"
# num = [100, 1000, 10_000, 100_000, 1_000_000, 10_000_000]
# dim = [100]
# float = "fp64"

# [[exp]]
# cmd = '{split_xla_flags} {cmd} {kind} -i "({num}, {dim})"'
# uid = './{rootdir}/{kind}/{float}-no_split/shape-{num}-{dim}'

# rootdir = "logs"
# split_xla_flags = 'XLA_FLAGS="--xla_disable_hlo_passes=split-intermediate-tensors"'
# kind = "outerprod-with-itself"
# num = [100, 1000, 10_000, 100_000, 1_000_000, 10_000_000]
# dim = [100]
# float = "fp64"

[[exp]]
cmd = 'XLA_FLAGS="--xla_try_split_tensor_size={limit}" {cmd} -f {float} -r {repeat} -w {warm} {kind} -k {kernel} -a "({num}, {dim})" -b "({num}, {dim})" -v "({num}, 1)"'
uid = './{rootdir}/{kind}/{float}-split_{limit}_{kernel}-{num}-{dim}'

limit = "15GB"
rootdir = "logs"
kind = "kvp"
kernel = ["se", "linear"]
num = [1000, 10_000, 100_000, 500_000, 1_000_000, 5_000_000]
dim = [10]
repeat = 5
warm = 1
float = "fp64"

# [[exp]]
# cmd = 'XLA_FLAGS="--xla_disable_hlo_passes=split-intermediate-tensors" {cmd} -f {float} {kind} -k {kernel} -a "({num}, {dim})" -b "({num}, {dim})" -v "({num}, 1)"'
# uid = './{rootdir}/{kind}/{float}-no_split/{kernel}-{num}-{dim}'

# rootdir = "logs"
# kind = "kernel-vector-product"
# kernel = ["se", "linear"]
# num = [100, 1000, 10_000, 100_000, 500_000, 1_000_000]
# dim = [10]
# float = "fp64"


[flags]
restart = false
num_proc = 4
gpu_indices = ["0", "1", "2", "4"]
