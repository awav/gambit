##### Build TensorFlow

STORAGE_PATH=~/Storage/tf-cuda11.2
rm -rf $STORAGE_PATH && bazel build //tensorflow/tools/pip_package:build_pip_package --config=cuda && ./bazel-bin/tensorflow/tools/pip_package/build_pip_package $STORAGE_PATH && pip uninstall tensorflow tensorflow-estimator && pip install -U $STORAGE_PATH/tensorflow-*.whl

##### Build JAX

cd jax
rm -rf /home/artem/code/jax/dist/jaxlib-*.whl && python build/build.py --enable_cuda && pip install --force-reinstall /home/artem/code/jax/dist/jaxlib-*.whl && pip install -e .

# kNN

TF_CPP_MIN_LOG_LEVEL=0 CUDA_VISIBLE_DEVICES="3" DUMPDIR="xla-knn-l2-uneven" XLA_FLAGS="--xla_try_split_tensor_size=100MB --xla_dump_hlo_as_dot --xla_dump_to=${DUMPDIR} --xla_enable_hlo_passes_only=split-intermediate-tensors,algebraic-rewriter,dce,broadcast-simplifier,cholesky_expander,triangular_solve_expander,bitcast_dtypes_expander,CallInliner,gpu_scatter_expander,rce-optimizer" python exp_knn.py -d random_n10000111_m10_d10 -k 10 -r 1 -w 1 -s 111 -c L2

TF_CPP_MIN_LOG_LEVEL=0 CUDA_VISIBLE_DEVICES="3" DUMPDIR="xla-knn-l2" XLA_FLAGS="--xla_try_split_tensor_size=100MB --xla_dump_hlo_as_dot --xla_dump_to=${DUMPDIR} --xla_enable_hlo_passes_only=split-intermediate-tensors,algebraic-rewriter,dce,broadcast-simplifier,cholesky_expander,triangular_solve_expander,bitcast_dtypes_expander,CallInliner,gpu_scatter_expander,rce-optimizer" python exp_knn.py -d random_n10000000_m10000_d100 -k 10 -r 1 -w 1 -s 111 -c L2

TF_CPP_MIN_LOG_LEVEL=0 CUDA_VISIBLE_DEVICES="3" DUMPDIR="xla-knn-l1" XLA_FLAGS="--xla_try_split_tensor_size=100MB --xla_dump_hlo_as_dot --xla_dump_to=${DUMPDIR} --xla_enable_hlo_passes_only=split-intermediate-tensors,algebraic-rewriter,dce,broadcast-simplifier,cholesky_expander,triangular_solve_expander,bitcast_dtypes_expander,CallInliner,gpu_scatter_expander,rce-optimizer" python exp_knn.py -d random_n10000000_m10000_d100 -k 10 -r 1 -w 1 -s 111 -c L1


CUDA_VISIBLE_DEVICES="3" XLA_FLAGS="--xla_try_split_tensor_size=1GB" python exp_knn.py -d random_n10000000_m10000_d100 -k 10 -r 1 -w 1 -s 111

# SGPR

XLA_FLAGS="--xla_try_split_tensor_size=100MB" python bench_sgpr_test.py -s 0 -m 1000


# JAX. Trax

TF_CPP_MIN_LOG_LEVEL=0 CUDA_VISIBLE_DEVICES="3" XLA_FLAGS="--xla_try_split_tensor_size=1GB" python -m trax.trainer --config_file=trax/trax/supervised/configs/reformer_imagenet64.gin
