{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Current File",
            "type": "python",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "env": {
                "TF_DUMP_GRAPH_PREFIX": "./xla-dump/",
                "XLA_FLAGS": "--xla_dump_hlo_as_text --xla_dump_hlo_as_dot --xla_dump_to=./xla-dump/",
                "TF_XLA_FLAGS": "--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit --tf_xla_enable_xla_devices --tf_xla_clustering_debug",
            },
            "justMyCode": false,
        },
        {
            "name": "SGPR: train",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/bench/exp_sgpr_ips.py",
            "console": "integratedTerminal",
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}:${workspaceFolder}/bench/",
                "CUDA_DEVICE_ORDER": "PCI_BUS_ID",
                "CUDA_VISIBLE_DEVICES": "0",
                // "TF_DUMP_GRAPH_PREFIX": "./xla-dump/",
                // "XLA_FLAGS": "--xla_dump_hlo_as_text --xla_dump_hlo_as_dot --xla_dump_to=./xla-dump/",
                // "TF_XLA_FLAGS": "--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit --tf_xla_enable_xla_devices --tf_xla_clustering_debug",
            },
            "justMyCode": false,
            "args": [
                "-d",
                "elevators",
                "-mi",
                "10",
                "-m",
                "1000",
                "--compile",
                "${input:compile}",
                "--no-train-ips",
            ],
        },
        {
            "name": "Exp: attention",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/bench/exp_attention.py",
            "console": "integratedTerminal",
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}:${workspaceFolder}/bench/",
                "CUDA_DEVICE_ORDER": "PCI_BUS_ID",
                "CUDA_VISIBLE_DEVICES": "0",
                // "TF_DUMP_GRAPH_PREFIX": "./xla-dump/",
                // "XLA_FLAGS": "--xla_dump_hlo_as_text --xla_dump_hlo_as_dot --xla_dump_to=./xla-dump/",
                // "TF_XLA_FLAGS": "--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit --tf_xla_enable_xla_devices --tf_xla_clustering_debug",
            },
            "justMyCode": false,
            "args": [
                "--sequence-len",
                "${input:sequence-len}",
                "--compile",
                "${input:compile}"
            ],
        },
        {
            "name": "Exp: transformer",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/bench/exp_transformer.py",
            "console": "integratedTerminal",
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}:${workspaceFolder}/bench/",
                "CUDA_DEVICE_ORDER": "PCI_BUS_ID",
                "CUDA_VISIBLE_DEVICES": "3",
                "XLA_FLAGS": "--xla_tensor_size_threshold=1GB --xla_tensor_split_size=1GB --xla_disable_hlo_passes=tensor-splitter",
                // "XLA_FLAGS": "--xla_dump_hlo_as_text --xla_dump_hlo_as_dot --xla_dump_to=./xla-dump/",
                // "TF_DUMP_GRAPH_PREFIX": "./xla-dump/",
                // "TF_XLA_FLAGS": "--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit --tf_xla_enable_xla_devices --tf_xla_clustering_debug",
            },
            "justMyCode": false,
            "args": [
                "--sequence-len",
                "${input:sequence-len}",
                "--compile",
                "${input:compile}"
            ],
        },
        {
            "name": "Plot: transformer",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/bench/exp_transformer_plot.py",
            "console": "integratedTerminal",
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}:${workspaceFolder}/bench/",
                "CUDA_DEVICE_ORDER": "PCI_BUS_ID",
                "CUDA_VISIBLE_DEVICES": "0",
                // "TF_DUMP_GRAPH_PREFIX": "./xla-dump/",
                // "XLA_FLAGS": "--xla_dump_hlo_as_text --xla_dump_hlo_as_dot --xla_dump_to=./xla-dump/",
                // "TF_XLA_FLAGS": "--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit --tf_xla_enable_xla_devices --tf_xla_clustering_debug",
            },
            "justMyCode": false,
            "args": [
                "${workspaceFolder}/${input:paths}",
            ],
        },
    ],
    "inputs": [
        {
            "type": "promptString",
            "id": "paths",
            "description": "File path (s)",
            "default": "/bench/logs/transformer-mem/*/bench.h5",
        },
        {
            "type": "promptString",
            "id": "sequence-len",
            "description": "Sequence length",
            "default": "1000",
        },
        {
            "type": "pickString",
            "id": "compile",
            "description": "Compilation options",
            "default": "xla",
            "options": [
                "xla",
                "tf",
                "none"
            ]
        }
    ]
}